[
  {
    "path": "posts/2021-03-23-adicion-conocida/",
    "title": "¿Cómo detectar el efecto matriz en un método analítico?",
    "description": "En este post trataremos el tema del efecto matriz de un método analítico y cómo detectarlo estadísticamente mediante el análisis de covarianza",
    "author": [
      {
        "name": "Carlos Gomez",
        "url": "https://www.analytical.cl"
      }
    ],
    "date": "2021-03-23",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroducción\r\nBibliografía\r\n\r\nIntroducción\r\nHe vuelto a postear, después de una gira que me llevó por los cinco… mentira, fue por pura pega.\r\nEl famoso efecto matriz, algo tan etéreo como el criterio analítico. El efecto matriz está íntimamente relacionado con las interferencias de la matriz que de alguna forma aumentan o disminuyen la señal instrumental que, en teoría, es producida sólo por el analito de interés.\r\nPara evaluar y detectar el efecto matriz, debemos desempolvar algunos papers que nos enseñaron el famoso método de calibración con adición conocida o adición de estándar. En este método, la matriz es nuestro medio de calibración. En vez de preparar los calibrantes en solventes puros o en solución ácida, utilizaremos la misma matriz para preparar (adicionar) el analito. De esta forma, la señal analítica de estos calibrantes, está compuesta de la señal propia del analito así como también de los interferentes, lo que permite corregir/minimizar sus efectos.\r\nExisten varias formas de implementar el método de adición conocida. Una muy buena referencia es el excelente y pedagógico paper de M. Bader:\r\n\r\nMorris Bader “A systematic approach to standard addition methods in instrumental analysis” J. Chem. Educ., 1980, 57 (10), p 703\r\n\r\nEl método consiste en añadir cantidades conocidas del analito en solvente puro o solución ácida a volúmenes iguales de matriz. Finalmente, medir la respuesta instrumental en una serie de adiciones crecientes tal como lo muestra la figura 1:\r\n\r\n\r\n\r\nFigure 1: Diseno experimental de la adicion conocida. Cortesia de Lins4y via Wikimedia Commons\r\n\r\n\r\n\r\nEs necesario que las adiciones de analito generen, en conjunto con la cantidad de analito presente en la muestra original, una concentración tal que aún se encuentre en el rango lineal de calibración. De esta forma se otiene una curva tal como se observa en la figura 2:\r\n\r\n\r\n\r\nFigure 2: Preparacion curva método de adicion conocida\r\n\r\n\r\n\r\nLas unidades del eje \\(X\\) pueden establecerse como analito añadido o, tal como lo propone Bader en su paper, como múltiplos de un volumen o cantidad fija del analito. Por lo tanto, en \\(x = 0\\) se obtiene la señal de la muestra problema a la cual no se le ha agregado el analito, es decir, la señal original. En cada una de las adiciones del estándar mediremos la señal instrumental de tal manera de obtener, y así lo esperamos, una relación lineal entre analito agregado \\(x\\) y señal \\(y\\) de la forma:\r\n\\[\\begin{equation}\r\n  y = \\beta_{0} + \\beta_{1}x + \\epsilon\r\n    \\tag{1}\r\n\\end{equation}\\]\r\ndonde se asumen los mismos supuestos que discutimos en el caso de la calibración lineal estándar(en solvente puro) y que puede recordar en este post.\r\nLa concentración de la muestra problema \\(C_{0}\\) se obtiene a partir de la ecuación (2):\r\n\\[\\begin{equation}\r\n  C_{0} = \\frac{\\beta_{0}}{\\beta_{1}}\r\n  \\tag{2}\r\n\\end{equation}\\]\r\nLa incertidumbre de la concentración de la muestra problema \\(u(C_{0})\\) se calcula a partir de la ecuación:\r\n\\[\\begin{equation}\r\n  u(C_{0}) = \\frac{\\sigma_{y/x}}{\\beta_{1}}\r\n  \\sqrt{\\frac{1}{n} + \\frac{\\overline{y}^2}\r\n  {\\beta_{1}\\sum_{i}^{n} (x_{i} - \\overline{x})^2}}\r\n    \\tag{3}\r\n\\end{equation}\\]\r\ndonde:\r\n\\(\\sigma_{y/x}\\) es la desviación estándar del error aleatorio \\(\\epsilon\\)\r\n\\(n\\) es el número de adiciones independientes del estándar\r\n\\(\\overline{y}\\) es el promedio de las señales instrumentales de las adiciones\r\n\\(\\overline{x}\\) es el promedio de las concentraciones\r\nComo puede apreciar, la expresión de la incertidumbre de calibración para el método de adición conocida es muy similar a la correspondiente calibración estandar que discutimos en un post anterior.\r\nSi queremos minimizar esta incertidumbre podríamos aumentar el número de adiciones \\(n\\) o aumentar el término \\(\\sum_{i}^{n} (x_{i} - \\overline{x})^2\\). Este último término es interesante, pues nos dice que la incertidumbre de calibración de este método se minimiza utilizando un rango amplio de concentración de adición. Ellison demuestra que, dado que la propiedad de linealidad se mantiene, basta preparar dos puntos de calibración:\r\nLa muestra original sin adición (\\(x = 0\\))\r\nEl extremo superior del rango lineal\r\nPor ejemplo, si por alguna razón se tuvieran que preparar \\(n = 6\\) adiciones, lo que indica la ecuación (3), es que sería mejor preparar tres puntos sin adición (\\(x = 0\\)) y tres en el extremos superior del rango lineal, tal como lo demuestra la figura 3\r\n\r\n\r\n\r\nFigure 3: Diseno de una curva de calibracion con adicion conocida para minimizar la incertidumbre\r\n\r\n\r\n\r\nPara evaluar estadísticamente si existe un efecto matriz debemos comparar la curva de calibración estándar (es decir, en solvente orgánico o en solución ácida) con la curva de adición conocida. Si las pendientes de ambas curvas son “iguales” podemos afirmar que no hay evidencia de efecto matriz tal como se muestra en la figura 4. De modo contrario, si las pendientes de ambas curvas difieren, entonces, existe un efecto matriz significativo, tal como lo indica la figura 5:\r\n\r\n\r\n\r\nFigure 4: Sin efecto matriz: calibracion estandar v/s adicion conocida\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 5: Con efecto matriz: calibracion estandar v/s adicion conocida\r\n\r\n\r\n\r\n\r\nAhora, Ud. se preguntará ¿Cuál es la herramienta estadística para comparar dos pendientes de curvas de calibración?\r\n\r\n¡Excelente pregunta Tu(x3)!\r\nAunque hay varias aproximaciones para hacer esta comparación, en este post utilizaremos el Análisis de Covarianza (ANCOVA) y lo implementaremos, como no, en lenguaje R. La siguiente tabla muestra los datos de calibración de clorpirifos en vino por GC-NPD, tanto en solvente puro como mediante el método de adición conocida en la muestra de vino:\r\n\r\n\r\n\r\nFigure 6: Tabla datos de calibracion clorpirifos\r\n\r\n\r\n\r\nNote que en la caso de la calibración estándar, las unidades de concentración están expresadas como \\(\\mu\\)g de clorpirifos por mL de solvente. En cambio, en los datos de adición conocida están expresadas como \\(\\mu\\)g de clorpirifos añadidos en los mL de muestra original. Por lo tanto, \\(X = 0\\, \\mu\\text{g}/\\text{mL}_{\\text{vino}}\\) representa la muestra sin adición. La figura 7 muestra las curvas de calibración correspondientes.\r\n\r\n\r\n\r\nFigure 7: Curvas de calibracion\r\n\r\n\r\n\r\nApliquemos, ahora, el análisis de covarianza para evaluar si existen diferencias significativas entre las pendientes.\r\nPrimero, ajustemos un modelo lineal para cada calibración:\r\n\r\n\r\n# Curva de calibración estándar\r\nx <- c(0, 0.1, 0.2, 0.3, 0.5, 1.0)\r\ny <- c(0, 80, 159, 245, 410, 795)\r\nfit.std <- lm(y ~ x)\r\n\r\n# Curva de adición conocida\r\nx.add <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5)\r\ny.add <- c(75, 159, 240, 328, 410, 498)\r\nfit.add <- lm(y.add ~ x.add)\r\n\r\n# En R la expresión y ~ x significa 'y es modelado por x'\r\n\r\n\r\n\r\nA continuación se muestran los análisis estadísticos para cada curva:\r\n\r\n\r\nCall:\r\nlm(formula = y ~ x)\r\n\r\nResiduals:\r\n     1      2      3      4      5      6 \r\n-2.489 -2.206 -2.924  3.359  8.924 -4.664 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)    2.489      3.420   0.728    0.507    \r\nx            797.176      7.105 112.193 3.78e-08 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 5.751 on 4 degrees of freedom\r\nMultiple R-squared:  0.9997,    Adjusted R-squared:  0.9996 \r\nF-statistic: 1.259e+04 on 1 and 4 DF,  p-value: 3.785e-08\r\n\r\n\r\n\r\nCall:\r\nlm(formula = y.add ~ x.add)\r\n\r\nResiduals:\r\n      1       2       3       4       5       6 \r\n 1.1429  0.6857 -2.7714  0.7714 -1.6857  1.8571 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)   73.857      1.463   50.49 9.21e-07 ***\r\nx.add        844.571      4.832  174.79 6.43e-09 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 2.021 on 4 degrees of freedom\r\nMultiple R-squared:  0.9999,    Adjusted R-squared:  0.9998 \r\nF-statistic: 3.055e+04 on 1 and 4 DF,  p-value: 6.426e-09\r\n\r\nLa pendiente de la curva de calibración estándar es 797 y la pendiente del método de adición es 845. ¿Es esta diferencia significativa? Esta es la pregunta que responde el ANCOVA. Para implementar este test en Rdebemos hacer una pequeña modificación a nuestra base de datos:\r\n\r\n\r\n\r\n\r\n\r\nX\r\n\r\n\r\nY\r\n\r\n\r\nCalibracion\r\n\r\n\r\n0.0\r\n\r\n\r\n0\r\n\r\n\r\nEstandar\r\n\r\n\r\n0.1\r\n\r\n\r\n80\r\n\r\n\r\nEstandar\r\n\r\n\r\n0.2\r\n\r\n\r\n159\r\n\r\n\r\nEstandar\r\n\r\n\r\n0.3\r\n\r\n\r\n245\r\n\r\n\r\nEstandar\r\n\r\n\r\n0.5\r\n\r\n\r\n410\r\n\r\n\r\nEstandar\r\n\r\n\r\n1.0\r\n\r\n\r\n795\r\n\r\n\r\nEstandar\r\n\r\n\r\n0.0\r\n\r\n\r\n75\r\n\r\n\r\nAdicion\r\n\r\n\r\n0.1\r\n\r\n\r\n159\r\n\r\n\r\nAdicion\r\n\r\n\r\n0.2\r\n\r\n\r\n240\r\n\r\n\r\nAdicion\r\n\r\n\r\n0.3\r\n\r\n\r\n328\r\n\r\n\r\nAdicion\r\n\r\n\r\n0.4\r\n\r\n\r\n410\r\n\r\n\r\nAdicion\r\n\r\n\r\n0.5\r\n\r\n\r\n498\r\n\r\n\r\nAdicion\r\n\r\n\r\nUna vez consolidados los datos en una única tabla podemos aplicar el análisis de covarianza en R con los siguientes comandos de la librería car:\r\n\r\nAnova Table (Type II tests)\r\n\r\nResponse: Y\r\n              Sum Sq Df   F value    Pr(>F)    \r\nX             540763  1 29108.930 1.558e-15 ***\r\nCalibracion    20535  1  1105.398 7.309e-10 ***\r\nX:Calibracion    310  1    16.699  0.003503 ** \r\nResiduals        149  8                        \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n\r\n\r\n\r\nDe la tabla se observa que el p-value de la comparación de las pendientes es \\(Pr(>F) = 0.0035\\) el cual es menor a 0.05 (X:Calibracion), por lo tanto, la diferencia observada entre las pendientes es, desde el punto de vista estadístico, significativa. Esto implica que existe un efecto matriz que no está corregido por la calibración en solvente. En definitiva, para este tipo de muestra, sería apropiado utilizar el método de adición conocida para la determinación de clorpirifos en vino.\r\nAhora, esta conclusión debe ser complementada con el criterio químico y metrológico. Recuerde que la desventaja del método de adición conocida es que es necesario hacer la adición muestra a muestra. Lo que se concluye del ANCOVA está basado en un criterio puramente estadístico.\r\nBueno estimado lector, espero haya disfrutado este post.\r\nEspero sus comentarios. Nos vemos.\r\nBibliografía\r\nEllison SL, Thompson M. Standard additions: myth and reality (2008) Analyst 133(8):992-7.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-23-adicion-conocida/mosaplot.png",
    "last_modified": "2021-03-23T19:23:22-03:00",
    "input_file": "adicion-conocida.utf8.md"
  },
  {
    "path": "posts/2021-03-23-incertidumbre-no-lineal/",
    "title": "Incertidumbre de una calibración no lineal con aplicación en química analítica",
    "description": "Se comparan tres métodos para estimar la incertidumbre de una calibración no lineal: Norma ISO 8466-2, GUM y Método de Monte Carlo",
    "author": [
      {
        "name": "Carlos Gomez",
        "url": "https://www.analytical.cl"
      }
    ],
    "date": "2020-06-06",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nEn un post anterior revisamos cómo estimar la incertidumbre de la concentración de una muestra problema, cuando ésta ha sido obtenida interpolando la señal instrumental en una curva de calibración lineal.\r\nLa expresión es relativamente simple y vimos también cómo podemos implementarla en el lenguaje de programación R a través del package chemCal.\r\nSin embargo, la vida no es tan sencilla. Recoradará estimad@ lector@ que está bastante documentada la presencia de desviaciones de la linealidad a altas concentraciones, fenómeno muy conocido en los métodos espectrofotométricos (Ley de Lambert-Beer). La severidad de estas desviaciones varía en función del detector, el analito y otros factores físico-químicos del sistema de medición.\r\nCuando existen estas desviaciones y deseamos llevar a cabo un test de linealidad, es muy probable que el test rechace el modelo lineal, por lo tanto, no podemos estimar la incertidumbre de calibración asumiendo este modelo. Si bien es cierto podemos reducir el rango lineal y diluir la muestra problema que está fuera del rango, la operación de dilución introduce nuevos errores (incluso errores humanos de transcripción bastante frecuentes).\r\nUna alternativa válida sería utilizar un modelo de calibración que capture esta no linealidad evitando así la dilución de la muestra, por lo tanto el problema se reduce a:\r\n\r\n¿Cómo estimar la incertidumbre de una muestra problema que ha sido obtenida a través de una curva de calibración no lineal?\r\n\r\nSin embargo, de esta pregunta se desprende al mismo tiempo otra interrogante:\r\n\r\n¿Cuál modelo de calibración no lineal utilizaré?\r\n\r\nExisten varios modelos de calibración no lineal:\r\nPolinomios\r\nNew Rational (en realidad se llaman aproximaciones de Padé)\r\nSplines\r\nLoess\r\netc.\r\nPor lo tanto, no existe una respuesta completamente correcta desde la prespectiva estadística, pues un modelo cuadrático sería tan válido como un polinomio cúbico. Desde el punto de vista químico podríamos preguntarnos ¿qué sentido químico tiene una curva de calibración polinómica de grado 5? ¿Son interpretables los parámetros del modelo? En un modelo lineal como el de Lambert-Beer: \\(y = \\beta_{0} + \\beta_{1}x\\) la pendiente de la curva de calibración tiene una interpretación química: es el producto entre coeficiente de extinción molar y la longitud de la celda:\r\n\\[\r\n\\underbrace{A}_\\text{y} = \\underbrace{\\epsilon \\cdot b}_\\text{$\\beta_{1}$} \\cdot\r\n\\underbrace{C}_\\text{x}\r\n\\tag{1}\r\n\\] Pero recuerde este sabio consejo de un monstruo de la estadística aplicada:\r\n\r\n“All models are wrong, but some are useful” – George Box\r\n\r\nPor lo tanto, tenemos que tomar una decisión. Y obviamente, como soy el autor de este humilde post, ya la tomé por Ud. En este artículo estimaremos la incertidumbre de calibración de un modelo polinómico de grado 2, también conocido como modelo cuadrático.\r\nNota: Desde el punto de vista estrictamente estadístico los modelos polinómicos, como la calibración cuadrática, son también modelos lineales ya que los coeficientes del modelo son lineales\r\n\\[y = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^2 + \\epsilon\\]\r\nEn cambio, en un modelo del tipo exponencial:\r\n\\[y = \\beta_{0}\\cdot e^{\\beta_{1}x}\\]\r\nEl coeficiente \\(\\beta_{1}\\) no es una función lineal.\r\nMétodos de estimación de incertidumbre de calibración\r\nEn este post ejemplificaremos y compararemos tres métodos de estimación de incertidumbre de calibración:\r\nNorma ISO 8466-2:2001 Water quality – Calibration and evaluation of analytical methods and estimation of performance characteristics – Part 2: Calibration strategy for non-linear second-order calibration functions.\r\nMétodo GUM\r\nMétodo de Monte Carlo (Suplemento 1 ISO-GUM)\r\nImplementaremos todos los métodos en el lenguaje de programación R, explicando paso a paso el código fuente con el fin de que Ud. obtenga los mismos resultados, es decir, un análisis reproducible.\r\nDatos de calibración\r\nPara ejemplificar los cálculos, utilizaremos los datos de calibración indicados en el ejemplo de la sección 7 de la norma ISO 8466-2. El siguiente código R nos permite ingresar los datos manualmente:\r\n\r\n\r\n# Ingresamos los datos de calibración de la sección 7 de la norma ISO 8466-2\r\n# x: concentración en mg/L\r\n# y: Absorbancia [UA]\r\n\r\nx <- c(12, 18, 24, 30, 36, 42, 48, 54, 60, 66)\r\ny <- c(0.083, 0.123, 0.164, 0.203, 0.240, 0.273, 0.303, 0.334, 0.364, 0.393)\r\n\r\nd <- data.frame(x, y) # creamos un data frame con las variables x e y (esto es\r\n                      # análogo a una matriz de datos en Excel con dos columnas)\r\n\r\n\r\n\r\nA continuación graficamos la curva de calibración con la librería ggplot2:\r\n\r\n\r\nlibrary(ggplot2) # cargamos la librería ggplot2\r\n\r\ntheme_set(theme_minimal()) # esto es sólo por una cuestión estética del gráfico\r\n\r\nggplot(d, aes(x = x, y = y)) +\r\n  geom_point(color = 'red') +\r\n  xlab('Concentración [mg/L]') +\r\n  ylab('Absorbancia [UA]')\r\n\r\n\r\n\r\n\r\nMmm… no sé Ud. pero yo veo una leve curvatura. Como lo vimos en un post anterior llevaremos a cabo un análisis estadístico básico para evaluar si el modelo de calibración lineal es adecuado, o si nos inclinamos por la hipótesis de no linealidad.\r\nComo no tenemos replicados de cada punto de calibración, haremos un Test de Linealidad de Mandel. Lo primero, es ajustar un modelo lineal a los datos \\(y = a + bx\\):\r\n\r\n\r\nfit.lineal <- lm(y ~ x, data = d) # ajustamos un modelo lineal y lo guardamos \r\n                                  # con el nombre fit.lineal\r\n\r\nparameters::model_parameters(fit.lineal) # parameters::model_parameters() \r\n\r\n\r\nParameter   | Coefficient |       SE |       95% CI |  t(8) |      p\r\n--------------------------------------------------------------------\r\n(Intercept) |        0.03 | 5.83e-03 | [0.01, 0.04] |  4.29 | 0.003 \r\nx           |    5.72e-03 | 1.37e-04 | [0.01, 0.01] | 41.80 | < .001\r\n\r\n                                         # simplemente nos ayuda\r\n                                         # a visualizar el análisis estadístico\r\n                                         # en una forma más ordenada\r\n\r\n\r\n\r\nEsta tabla nos dice que el intercepto del modelo es \\(a = 0.0250303\\) y la pendiente \\(b = 0.0057172\\). Note el alto coeficiente de determinación \\(r^{2} = 0.9954\\) lo cual indica que es un buen modelo. El coeficiente de correlación es \\(r = 0.998\\) que si bien es un dato a considerar, no es una prueba formal de linealidad.\r\nLa siguiente figura muestra el ajuste lineal sobre los datos de calibración:\r\n\r\n\r\nlibrary(ggpmisc) # para escribir ecuaciones dentro del gráfico\r\n\r\nggplot(d, aes(x = x, y = y)) +\r\n  geom_point(color = 'red') +\r\n  geom_smooth(method = 'lm', se = F, \r\n              size = 0.5) + # dibuja la curva de calibración lineal\r\n  xlab('Concentración [mg/L]') +\r\n  ylab('Absorbancia [UA]') +\r\n  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), \r\n                                  sep = \"*\\\", \\\"*\")), \r\n               formula = y ~ x, \r\n               parse = TRUE, \r\n               rr.digits = 4)\r\n\r\n\r\n\r\n\r\nSe observa que el ajuste lineal no es un buen modelo, pues no captura la curvatura de los datos a pesar del alto coeficiente de correlación. Esto se oberva más claramente si obervamos el gráfico de residuos:\r\n\r\n\r\nplot(fit.lineal, which = 1, add.smooth = F, pch = 19, col = 'red', \r\n     main = 'Gráfico de residuos modelo lineal')\r\n\r\n\r\n\r\n\r\nLa evidencia en contra del modelo lineal es abrumadora, el gráfico muestra claramente un patrón en los residuos que indica que el modelo lineal no es adecuado. Sin embargo, a pesar de la evidencia, haremos el Test de Mandel para “comprobar” esta hipótesis. Para aplicar el Test de Mandel debemos ahora ajustar el modelo cuadrático y compararlo con el modelo lineal. Para ser consistentes en la notación de la norma ISO 8466-2, definiremos el modelo de calibración cuadrático como:\r\n\\[ \r\ny = a + bx + cx^2\r\n\\]\r\n\r\n\r\nfit.nolineal <- lm(y ~ x + I(x^2), data = d) # ajuste cuadrático y los guardamos \r\n                                          # con el nombre fit.nolineal\r\nparameters::model_parameters(fit.nolineal)\r\n\r\n\r\nParameter   | Coefficient |       SE |         95% CI |   t(7) |      p\r\n-----------------------------------------------------------------------\r\n(Intercept) |   -5.62e-03 | 2.47e-03 | [-0.01,  0.00] |  -2.27 | 0.057 \r\nx           |    7.67e-03 | 1.42e-04 | [ 0.01,  0.01] |  54.01 | < .001\r\nx^2         |   -2.50e-05 | 1.79e-06 | [ 0.00,  0.00] | -14.01 | < .001\r\n\r\nSe obtiene una tabla similar que la del modelo lineal, con la adición del coeficiente que acompaña al \\(x^2\\): I(x^2) \\(= -2.504\\times 10^{-5}\\). Note que el coeficiente de determinación del modelo cuadrático es mayor que el del modelo lineal. Esto siempre se cumplirá, lo que hace el Test de Mandel es discernir si esta “mejora” en el modelo es “significativa”.\r\nLa siguiente figura muestra el ajuste no lineal, el cual captura mucho mejor la curvatura de los datos:\r\n\r\n\r\nggplot(d, aes(x = x, y = y)) +\r\n  geom_point(color = 'red') +\r\n  geom_smooth(method = 'lm',         # dibuja la curva de calibración no lineal\r\n              se = F, \r\n              formula = y ~ x + I(x^2), size = 0.5) + \r\n  xlab('Concentración [mg/L]') +\r\n  ylab('Absorbancia [UA]') +\r\n  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), \r\n                                  sep = \"*\\\", \\\"*\")),\r\n               formula = y ~ x + I(x^2), \r\n               parse = TRUE, \r\n               rr.digits = 4)\r\n\r\n\r\n\r\n\r\nOk, aplicamos el Test de Mandel con el comando anova:\r\n\r\n\r\nparameters::model_parameters(anova(fit.lineal, fit.nolineal))\r\n\r\n\r\nParameter               |      RSS | Sum_Squares | df | df (error) | Mean_Square |      F |      p\r\n--------------------------------------------------------------------------------------------------\r\nModel 1: y ~ x          | 4.44e-04 |             |    |          8 |             |        |       \r\nModel 2: y ~ x + I(x^2) | 1.53e-05 |    4.29e-04 |  1 |          7 |    4.29e-04 | 196.29 | < .001\r\n\r\n\r\n\r\n\r\nEl p-value del test de Mandel es \\(2.23\\times 10^{-6}\\), el cual de acuerdo a la interpretación tradicional, indica que el modelo lineal no es adecuado para los datos de calibración.\r\nProcedamos, entonces, a estimar la incertidumbre de la concentración \\(\\hat{x}\\) de una muestra problema, cuyo valor fue obtenido interpolando la señal instrumental en el modelo de calibración no lineal.\r\nEstimación de incertidumbre de acuerdo a ISO 8466-2\r\nDesde el punto de vista metrológico, la aproximación que indica esta norma es similar a lo que dicta la guía ISO GUM clásica, es decir, estima la incertidumbre a partir de un modelo de medición \\(y = f(x)\\). La “gracia” de esta norma es que nos ahorra tinta, pues la ecuación de incertidumbre ya está “algebraicamente manipulada”. No entraremos en los detalles de las primeras secciones de la norma los cuales estudian el comportamiento de la curvatura, es decir, si será posible encontrar un máximo o un mínimo, lo cual es clave en la utilidad del modelo cuadrático como función de calibración. Esto es importante porque recuerde que una función parabólica tiene dos soluciones, si existiera un máximo o un mínimo en el rango de trabajo, el modelo cuadrático no puede ser utilizado como función de calibración.\r\nLa siguiente ecuación calcula la incertidumbre expandida \\(I(\\hat{x}) = U_{\\hat{x}}\\) de la concentración de la muestra problema \\(\\hat{x}\\), interpolada en la curva de calibración no lineal \\(y = a + bx + cx^2\\). Corresponde a la ecuación (27) de la norma:\r\n\\[\r\nI(\\hat{x}) = \\frac{s_{y} \\cdot t_{n - 3,\\, 95\\%}}{b + 2c\\hat{x}} \\cdot\r\n            \\sqrt{\\frac{1}{N} + \\frac{1}{\\hat{N}} + \r\n            \\frac{(\\hat{x} - \\overline{x})^2 \\, Q_{x^4} + \r\n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right)^2 Q_{xx} -\r\n            2(\\hat{x} - \\overline{x}) \r\n            \\left(\\hat{x}^2 - \\frac{\\sum x_{i}^{2}}{N} \\right) Q_{x^3}}\r\n            {Q_{x^4} Q_{xx} - \\left( Q_{x^3} \\right)^2}}\r\n\\]\r\ndonde:\r\n\\[\r\ns_{y} = \\sqrt{\\frac{\\sum (y_{i} -\\hat{y})^2}{N - 3}}\r\n\\]\r\n\\(y_{i}\\) es la respuesta experimental observada del estándar \\(i\\), \\(\\hat{y}\\) es la respuesta instrumental que predice el modelo para el mismo estándar \\(i\\), por lo tanto \\(e_{i} = y_{i} - \\hat{y}\\) es el residuo. \\(N\\) es el número de calibrantes. ¿Por qué el denominador es \\(N - 3\\) y no \\(N -2\\) como en la calibración lineal? Porque el modelo cuadrático posee tres parámetros \\(a\\), \\(b\\) y \\(c\\).\r\n\\(t_{N - 3,\\, 95\\%}\\) es el valor del T de Student con \\(N - 3\\) grados de libertad y un 95% de confianza.\r\n\\(\\hat{N}\\) es el número de replicados independientes de la muestra problema. Como discutimos en otro post, esto no corresponde a inyectar \\(\\hat{N}\\) veces la misma muestra en el instrumento.\r\n\\(\\hat{x}\\) es la concentración de la muestra problema interpolada en la curva de calibración no lineal, la cual se obtiene resolviendo la ecuación cuadrática. Como Ud. recordará de sus años mozos esto siginifica que la concentración interpolada se obtiene a partir de:\r\n\\[\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}\\] donde \\(y_{0}\\) es la señal instrumental de la muestra problema.\r\n\\(x_{i}\\) es la concentración del estándar \\(i\\)\r\n\\(\\overline{x} = \\sum_{i = 1}^{N} x_{i}\\) es el promedio de las concentraciones de los calibrantes.\r\nFinalmente:\r\n\\[\r\n\\begin{aligned}\r\nQ_{xx}  &= \\sum x_{i}^2 - \\frac{\\left(\\sum x_{i}\\right)^2}{N} \\\\\r\nQ_{x^3} &= \\sum x_{i}^3 - \\left(\\sum x_{i} \\times \\frac{\\sum x_{i}^2}{N}\\right) \\\\\r\nQ_{x^4} &= \\sum x_{i}^4 - \\frac{\\left(\\sum x_{i}^2\\right)^2}{N}\r\n\\end{aligned}\r\n\\]\r\nOk, nada del otro mundo. Es bien fea, pero sólo son operaciones de aritmética básica. Algunas observaciones:\r\nComo Ud. recordará en el caso de la calibración lineal, a partir de esta ecuación podemos inferir que si deseamos minimizar la incertidumbre de calibración no lineal podemos :\r\nAumentar el número de calibrantes \\(N\\)\r\nAumentar el número de replicados independientes de la muestra problema \\(\\hat{N}\\)\r\nAumentar la sensibilidad del método, que en el caso de la calibración cuadrática está dada por \\(b + 2c\\hat{x}\\), es decir, depende de la concentración de la muestra problema \\(\\hat{x}\\). En cambio, en la calibración lineal la sensibilidad era constante en todo el rango de concentración estudiado y correspondía a la pediente de la curva.\r\nEn el caso de la calibración lineal, la incertidumbre de calibración se minimiza en el centroide de la curva, en el caso del modelo cuadrático esto no siempre es así. Observe en la siguiente figura las bandas de confianza de ambos tipos de calibración:\r\n\r\n\r\n\r\nAdvierta que ambos modelos comparten la propiedad que la mayor incertidumbre se encuentra en los extremos. Sin embargo, en la calibración cuadrática, para este conjunto de datos, la menor incertidumbre no está en el centro de la curva.\r\nOk, a continuación implementaremos la ecuación de incertidumbre en R con los datos del ejemplo de la sección 7 de la norma. La señal instrumental de la muestra problema es \\(y_{0} = 0.084\\) UA:\r\n\r\n\r\nN <- length(x) # Número de calibrantes\r\nN.hat <- 1     # Número de replicados de la muestra problema\r\nQxx <- sum(x^2) - sum(x)^2/N\r\nQx3 <- sum(x^3) -(sum(x) * sum(x^2)/N)\r\nQx4 <- sum(x^4) - sum(x^2)^2/N\r\n\r\na <- fit.nolineal$coefficients[1]\r\nb <- fit.nolineal$coefficients[2]\r\nc <- fit.nolineal$coefficients[3]\r\n\r\ns.y <- summary(fit.nolineal)$sigma # Es lo que R denomina Residual standard error\r\nt <- qt(0.975, N - 3) # El T de Student (¡Ya no se usan tablas!)\r\n\r\ny0 <- 0.084 # Es la señal instrumental de la muestra problema\r\nx.hat <- (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c) # Concentración de la muestra\r\n\r\nIx <- (s.y * t)/(b + 2*c*x.hat) * sqrt(\r\n  1/N + 1/N.hat + ((x.hat - mean(x))^2*Qx4 + (x.hat^2 - sum(x^2)/N)^2 * Qxx -  \r\n  2*(x.hat - mean(x))*(x.hat^2 - sum(x^2)/N)*Qx3)/\r\n  (Qx4 * Qxx - Qx3^2)\r\n)\r\n\r\nIx <- unname(Ix) # Simplemente es para dejar sólo el número\r\n\r\n\r\n\r\nLa concentración de la muestra es \\(\\hat{x} = 12.17\\) mg/L. Al aplicar esta metodología obtenemos una incertidumbre expandida de \\(I(\\hat{x}) = 0.63\\) mg/L, es decir, exactamente la misma que la que indica la norma ISO. Note que si Ud. quisiera combinar esta incertidumbre de calibración con algún otro factor (p.ej: masa de la muestra, volumen de aforo, etc.) debe primero tansformarla en incertidumbre estándar, dividiéndola por el factor de cobertura \\(k\\), que en este caso corresponde al t Student con \\(N - 3\\) grados de libertad al 95% de confianza (k = 2.36):\r\n\\[\r\nu_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = 0.27\\, \\, \\text{mg/L}\r\n\\] Por lo tanto, si tuviéramos que informar el resultado de la concentración de la muestra interpolada en la curva de calibración no lineal informaríamos \\(12.17 \\pm 0.63\\) mg/L [nota mental: mmmm… esto de las cifras significativas da para otro post, pero dejémoslo así por ahora. No olvidar borrar este comentario.]\r\n¿Cómo varía esta incertidumbre de calibración no lineal con la concentración de la muestra? La siguiente figura muestra esta variación:\r\n\r\n\r\nx <- seq(12, 66, by = 6) # Rango de concentración\r\nN <- length(x)\r\nN.hat <- 1\r\nmu.x <- mean(x) # promedio de las concentraciones de los calibrantes\r\nsq.x <- sum(x^2) # suma de las concentraciones de los calibrantes al cuadrado\r\nQxx <- sum(x^2) - sum(x)^2/N\r\nQx3 <- sum(x^3) -(sum(x) * sum(x^2)/N)\r\nQx4 <- sum(x^4) - sum(x^2)^2/N\r\nt <- qt(0.975, N - 3)\r\n\r\n# Para graficar la incertidumbre vs concentración, primero debemos crear una\r\n# función que tome un X (una concentración) y calcule el Y (incertidumbre)\r\nUx <- function(x) {\r\n    U <- s.y*t/(b + 2*c*x) * sqrt(\r\n    1/N + 1/N.hat + ((x - mu.x)^2*Qx4 + (x^2 - sq.x/N)^2 * Qxx -  \r\n    2*(x - mu.x)*(x^2 - sq.x/N)*Qx3)/\r\n    (Qx4 * Qxx - Qx3^2))\r\n    return(unname(U))\r\n}\r\n\r\n# Graficamos concentración (X) vs Incertidumbre (Y)\r\n\r\nplot(x, Ux(x), type = 'n',\r\n     main = 'Concentración vs Incertidumbre de calibración',\r\n     xlab = 'Concentración [mg/L]',\r\n     ylab = 'Incertidumbre expandida [mg/L]')\r\nlines(spline(x, Ux(x)), col = 'red')\r\n\r\n\r\n\r\n\r\nSe aprecia que la incertidumbre aumenta con la concentración en una forma no constante para concentraciones mayores a 20 mg/L. Tal como mencionamos anteriormente, el mínimo no se encuentra en el centro del rango de concentración como ocurre con la calibración lineal. Para encontrar el valor exacto de concentración que minimiza la incertidumbre en este rango, usamos el comando optimize:\r\n\r\n\r\n# Busca el mínimo de la función Ux en el intervalo de 12 a 66 mg/L\r\noptimize(Ux, interval = c(12, 66))\r\n\r\n\r\n$minimum\r\n[1] 20.29164\r\n\r\n$objective\r\n[1] 0.5808116\r\n\r\nLa concentración que minimiza la incertidumbre es 20.29 mg/L.\r\nMuy entretenido, pero la vida es corta y debemos ser eficientes por lo tanto, para evitarnos el “tedio” de implementar la fórmula a mano, utilizaremos el package investr el cual calcula exactamente la incertidumbre de calibración de un gran número de modelos de calibración, entre ellos, los modelos cuadráticos:\r\n\r\n\r\n# y0 es la señal de la muestra problema y0 = 0.084 UA\r\nlibrary(investr) # Cargamos la librería investr\r\nx.hat <- invest(fit.nolineal, data = d, y0 = y0, interval = 'Wald')\r\nx.hat\r\n\r\n\r\n  estimate      lower      upper         se \r\n12.1672952 11.5400416 12.7945488  0.2652656 \r\n\r\ndonde:\r\nestimate es la concentración de la muestra problema\r\nupper es el extremo superior de la incertidumbre expandida \\(I(\\hat{x})\\)\r\nlower es el extremo inferior de la incertidumbre expandida \\(I(\\hat{x})\\)\r\nse es la incertidumbre estándar de calibración \\(u_{\\hat{x}}\\), la cual es exactamente igual a la obtenida por la fórmula anterior \\(u_{\\hat{x}} = \\frac{U_{\\hat{x}}}{k} = 0.27\\, \\, \\text{mg/L}\\)\r\nNote que si quisiéramos obener \\(I(\\hat{x})\\) a partir de esta tabla, tendríamos que hacer la siguiente operación \\(I(\\hat{x}) =\\) upper - estimate:\r\n\r\n\r\nx.hat$upper - x.hat$estimate\r\n\r\n\r\n[1] 0.6272536\r\n\r\nNo podemos usar el package chemCal que utilizamos en un post anterior para estimar la incertidumbre de calibración, porque este package sólo soporta calibraciones lineales.\r\nEstimación de incertidumbre mediante Guía ISO GUM\r\nYa que la señal instrumental es una función de la concentración, entonces, podemos utilizar la aproximación ISO GUM clásica para estimar la incertidumbre de calibración. Por “clásica” me refiero a utilizar la aproximación de Taylor con las derivadas parciales. Esta guía dice lo siguiente:\r\nExpresar el mensurando como una ecuación de medición a través de una relación funcional con las magnitudes de entrada. En este caso el mensurando es la concentración \\(\\hat{x}\\) cuya ecuación de medición es la solución de la ecuación cuadrática \\(y_{0} = a + b\\hat{x} + c\\hat{x^2}\\) donde \\(y_{0}\\) es la señal de la muestra problema:\r\n\\[\r\n\\hat{x} = \\frac{-b \\pm \\sqrt{b^2 - 4(a - y_{0})c}}{2c}\r\n\\] 2. Identificación de las fuentes de incertidumbre. Al observar la ecuación de medición identificamos las siguientes fuentes de incertidumbre:\r\nParámetros del modelo cuadrático: \\(a\\), \\(b\\) y \\(c\\)\r\nSeñal instrumental de la muestra problema \\(y_{0}\\)\r\nEvaluación de las fuentes de incertidumbre:\r\nLas incertidumbres estándar de los parámetros del modelo pueden ser obtenidas directamente del ajuste cuadrático fit.nolineal:\r\n\r\n\r\n# parámetros del modelo\r\na <- fit.nolineal$coeff[1]\r\nb <- fit.nolineal$coeff[2]\r\nc <- fit.nolineal$coeff[3]\r\n\r\n# las incertidumbres estándar de a, b y c las obtenemos con la función summary\r\nua <- summary(fit.nolineal)$coefficients[1, 2]\r\nub <- summary(fit.nolineal)$coefficients[2, 2]\r\nuc <- summary(fit.nolineal)$coefficients[3, 2]\r\n\r\n\r\n\r\nLa incertidumbre estándar de la señal instrumental de la muestra problema también puede obtenerse del ajuste cuadrático y corresponde a la desviación estándar residual:\r\n\r\n\r\nuy0 <- summary(fit.nolineal)$sigma\r\ny0 <- 0.084 # dato del problema, es decir, la absorbancia de la muestra\r\n\r\n\r\n\r\nDeterminación de la incertidumbre estándar combinada \\(u_{\\hat{x}}\\) a través de la expresión:\r\n\\[\r\nu_{\\hat{x}}^2 = \\left( \\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}}\\right) ^{2} (u_{y_{0}})^{2} + \r\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{a}}\\right) ^{2} (u_{a})^{2} + \r\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{b}}\\right) ^{2} (u_{b})^{2} +\r\n\\left( \\frac{\\partial{\\hat{x}}}{\\partial{c}}\\right )^{2} (u_{c})^{2}\r\n\\]\r\n“sólo” nos falta obtener las derivadas parciales (aguante ese código \\(\\LaTeX\\)):\r\n\\[\r\n\\begin{aligned}\r\n\\frac{\\partial{\\hat{x}}}{\\partial{y_{0}}} &= \r\n\\frac{1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\r\n\\frac{\\partial{\\hat{x}}}{\\partial{a}} &=\r\n  \\frac{-1}{\\sqrt{b^{2} - 4c(a-y_{0})}} \\\\\r\n\\frac{\\partial{\\hat{x}}}{\\partial{b}} &=\r\n\\frac{-1 + \\frac{b}{\\sqrt{b^{2} - 4c(a-y_{0})}}}{2c} \\\\\r\n\\frac{\\partial{\\hat{x}}}{\\partial{c}} &=\r\n  \\frac{-a + y_{0}}{c\\sqrt{b^{2} - 4c(a-y_{0})}} - \r\n  \\frac{-b + \\sqrt{b^{2} - 4c(a-y_{0})}}{2c^{2}}\r\n\\end{aligned}\r\n\\]\r\n¡Listo! ahora debemos evaluar las expresiones. Pero como soy flojo, prefiero usar el excelente package metRology que hará todo el trabajo por mí:\r\n\r\n\r\nlibrary(metRology) # cargamos la librería\r\n\r\nexpr <- expression((-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c)) # ecuación de medición\r\nx <- list(a = a, b = b, c = c, y0 = y0) # valores de cada X input\r\nu <- c(ua, ub, uc, uy0) # incertidumbres estándar de cada X input\r\nu.GUM <- uncert(expr, x, u, method = 'GUM') # Usamos el método GUM\r\nu.GUM\r\n\r\n\r\n\r\nUncertainty evaluation\r\n\r\nCall:\r\n  uncert.expression(obj = expr, x = x, u = u, method = \"GUM\")\r\n\r\nExpression: (-b + sqrt(b^2 - 4 * (a - y0) * c))/(2 * c)\r\n\r\nEvaluation method:  GUM \r\n\r\nUncertainty budget:\r\n   x             u            c           u.c        \r\na  -5.621212e-03 2.474778e-03   -141.6217 -0.35048212\r\nb   7.670455e-03 1.420320e-04  -1723.1492 -0.24474238\r\nc  -2.504209e-05 1.787394e-06 -20966.0252 -0.03747454\r\ny0  8.400000e-02 1.478563e-03    141.6217  0.20939648\r\n\r\n   y:  12.16727\r\nu(y):  0.4774807 \r\n\r\n¿What? ¿Por qué obtuvimos una incertidumbre estándar de 0.477 y no la que calculamos con la ecuación de la norma ISO 0.265? Por la sencilla razón de que los parámetros de un modelo cuadrático no son independientes, sus covarianzas no son 0. Es más, algunas de las covarianzas son negativas. Observe la siguiente figura que fue obtenida simulando curvas de calibración cuadráticas. En la figura se muestra las correlaciones entre los tres parámetros del modelo no lineal:\r\n\r\n\r\n# Simularemos p = 200 curvas de calibración cuadráticas a partir de los datos \r\n# empíricos \r\n\r\np <- 200 # Número de simulaciones\r\na.sim <- numeric(p) # vector que guardará el parámetro a\r\nb.sim <- numeric(p) # vector que guardará el parámetro b\r\nc.sim <- numeric(p) # vector que guardará el parámetro c\r\n\r\n# Hacemos un loop\r\nfor(i in 1:p){\r\n  x.sim <- seq(12, 66, by = 6)\r\n  y.sim <- a + b*x.sim + c*x.sim^2 + rnorm(length(x.sim), 0, uy0)\r\n  fit.nolineal.sim <- lm(y.sim ~ x.sim + I(x.sim^2))\r\n  a.sim[i] <- fit.nolineal.sim$coeff[1]\r\n  b.sim[i] <- fit.nolineal.sim$coeff[2]\r\n  c.sim[i] <- fit.nolineal.sim$coeff[3]\r\n}\r\n\r\n# guardamos los parámetros simulados en un data frame que llamamos param.sim\r\nparam.sim <- data.frame(a.sim, b.sim, c.sim) \r\n                                                \r\n# graficamos los parámetros simulados\r\nplot(param.sim)\r\n\r\n\r\n\r\n\r\nSe advierte claramente que existe una correlación negativa entre los parámetros \\(a\\) y \\(b\\), además entre \\(b\\) y \\(c\\). La correlación entre \\(a\\) y \\(c\\) es positiva. En rigor, habría que incorporar las derivadas parciales cruzadas y las covarianzas entre los parámetros. De sólo pensarlo, me dan ganas de procastinar aún más la escritura de este post, así que recurriremos al package metRology.\r\nLa parte “fácil” es obtener la matriz de covarianzas de los parámetros del modelo con el comando vcov:\r\n\r\n\r\nv <- vcov(fit.nolineal)\r\ncolnames(v) <- c('a', 'b', 'c') # solo cosmética para que aparezcan los nombres\r\nrownames(v) <- c('a', 'b', 'c') # de los parámetros (es opcional)\r\nv\r\n\r\n\r\n              a             b             c\r\na  6.124524e-06 -3.337187e-07  3.910406e-09\r\nb -3.337187e-07  2.017310e-08 -2.491926e-10\r\nc  3.910406e-09 -2.491926e-10  3.194776e-12\r\n\r\nLa diagonal de esta matriz es precisamente la incertidumbre estándar al cuadrado de los parámetros (a.k.a sus varianzas). Si queremos, también podemos expresarla como matriz de correlaciones con el comando cov2cor:\r\n\r\n\r\nparam.cor <- cov2cor(v)\r\nparam.cor\r\n\r\n\r\n           a          b          c\r\na  1.0000000 -0.9494193  0.8840269\r\nb -0.9494193  1.0000000 -0.9815865\r\nc  0.8840269 -0.9815865  1.0000000\r\n\r\nEn la diagonal de esta matriz obviamente esperamos correlación 1. Se observa claramente la alta correlación entre los parámetros, como dijimos anteriormente, algunas de ellas son negativas.\r\nLa parte “difícil” es que debemos incorporar la variable señal instrumental de la muestra problema \\(y_{0}\\), la cual obviamente es independiente de los parámetros del modelo:\r\n\r\n\r\n# Incorporamos la variable y0 que es independiente de los parámetros\r\nv <- rbind(v, y0 = rep(0, 3)) \r\nv <- cbind(v, y0 = rep(0, 4))\r\nv[4, 4] <- uy0^2 # Asignamos al elemento de la 4a fila y 4a columna  \r\n                 # la varianza de y0\r\nv\r\n\r\n\r\n               a             b             c           y0\r\na   6.124524e-06 -3.337187e-07  3.910406e-09 0.000000e+00\r\nb  -3.337187e-07  2.017310e-08 -2.491926e-10 0.000000e+00\r\nc   3.910406e-09 -2.491926e-10  3.194776e-12 0.000000e+00\r\ny0  0.000000e+00  0.000000e+00  0.000000e+00 2.186147e-06\r\n\r\nAhora, incorporamos las covarianzas en el cálculo por método GUM:\r\n\r\n\r\nu.GUM.cov <- uncert(expr, x, cov = v, method = \"GUM\")\r\nu.GUM.cov\r\n\r\n\r\n\r\nUncertainty evaluation\r\n\r\nCall:\r\n  uncert.expression(obj = expr, x = x, method = \"GUM\", cov = v)\r\n\r\nExpression: (-b + sqrt(b^2 - 4 * (a - y0) * c))/(2 * c)\r\n\r\nEvaluation method:  GUM \r\n\r\nUncertainty budget:\r\n   x             u            c           u.c        \r\na  -5.621212e-03 2.474778e-03   -141.6217 -0.35048212\r\nb   7.670455e-03 1.420320e-04  -1723.1492 -0.24474238\r\nc  -2.504209e-05 1.787394e-06 -20966.0252 -0.03747454\r\ny0  8.400000e-02 1.478563e-03    141.6217  0.20939648\r\n\r\n   y:  12.16727\r\nu(y):  0.2651904 \r\n\r\n¡Perfecto!, ahora sí, al incluir las covarianzas obtenemos resultados consistentes con el método descrito en la norma ISO 8466-2.\r\nEstimación con el Método de Monte Carlo\r\nNo detallaremos aquí cómo funciona el método de Monte Carlo, puede consultarlo en este post y en este otro.\r\nSería super simple si usamos el package metRology, el problema es que el package lanza un error numérico cuando existen covarianzas negativas. Probé el ejemplo que incluye el manual de metRology y el error se repite. Es un problema al evaluar la suma de las correlaciones. Le consulté al autor Steve Ellison, sin embargo, a la fecha (09 de junio 2020) aún no tengo respuesta, a pesar de que Steve siempre responde las consultas en forma muy expedita. Otros usuarios han tenido un problema similar y se ha abierto un hilo en stackoverflow.\r\nPor lo tanto, implementamos el método de Monte Carlo “a mano” utilizando el package MASS el cual permite generar muestras aleatorias multivariadas incluyendo las correlaciones:\r\n\r\n\r\n# No funciona metRology MC así que lo hicimos a mano\r\nlibrary(MASS) # cargamos la librería\r\n\r\n# Generamos n muestras aleatorias multivariadas, cuyas medias \r\n# corresponden a los valores de a, b, c e y0\r\n# La matriz de covarianza Sigma = v la calculamos anteriormente\r\n\r\nset.seed(123) # Para que Ud. obtenga los mismos resultados\r\nmuestra.MC <- mvrnorm(n = 10000, mu = c(a, b, c, y0), Sigma = v, empirical = T)\r\ncolnames(muestra.MC) <- c('a', 'b', 'c', 'y0') # solo cosmética\r\nmuestra.MC <- data.frame(muestra.MC) # lo guardamos como data.frame\r\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\r\n\r\n\r\n             a           b             c         y0\r\n1 -0.004872147 0.007615757 -2.422806e-05 0.08771566\r\n2 -0.004584974 0.007614935 -2.439880e-05 0.08385741\r\n3 -0.005903886 0.007685426 -2.569142e-05 0.08643112\r\n4 -0.004770996 0.007561121 -2.367442e-05 0.08417975\r\n5 -0.003113309 0.007559284 -2.403774e-05 0.08478106\r\n6 -0.006100136 0.007724920 -2.626908e-05 0.08644533\r\n\r\nCada fila es una simulación. Si, por ejemplo, calculamos el promedio de cada variable simulada, obtenemos un valor similar a los valores empíricos. A mayor número de simulaciones, más nos acercamos a valores que asumimos como verdaderos.\r\n\r\n\r\napply(muestra.MC, 2, mean) # promedio de cada columna\r\n\r\n\r\n            a             b             c            y0 \r\n-5.621212e-03  7.670455e-03 -2.504209e-05  8.400000e-02 \r\n\r\nBien, lo que tenemos que hacer es que en cada simulación debemos calcular la concentración de la muestra:\r\n\r\n\r\n# cargaré estas librerías sólo para facilitar la manipulación de los datos\r\nlibrary(magrittr)\r\nlibrary(tidyverse)\r\n\r\n# Creamos una nueva variable llamada x.hat que corresponde a la concentración de\r\n# la muestra\r\nmuestra.MC <- muestra.MC %>% \r\n  mutate(x.hat = (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c))\r\nhead(muestra.MC) # muestra las primeras n = 6 simulaciones\r\n\r\n\r\n             a           b             c         y0    x.hat\r\n1 -0.004872147 0.007615757 -2.422806e-05 0.08771566 12.66792\r\n2 -0.004584974 0.007614935 -2.439880e-05 0.08385741 12.08205\r\n3 -0.005903886 0.007685426 -2.569142e-05 0.08643112 12.53997\r\n4 -0.004770996 0.007561121 -2.367442e-05 0.08417975 12.23276\r\n5 -0.003113309 0.007559284 -2.403774e-05 0.08478106 12.09232\r\n6 -0.006100136 0.007724920 -2.626908e-05 0.08644533 12.51252\r\n\r\nLa última columna corresponde a la concentración calculada para cada simulación. Por lo tanto, si queremos obtener la incertidumbre estándar de la concentración, basta calcular la desviación estándar de esa columna:\r\n\r\n\r\nmu.x.hat.MC <- mean(muestra.MC$x.hat) # valor promedio de concentración\r\nu.x.hat.MC <- sd(muestra.MC$x.hat) # incertidumbre estándar de la concentración\r\nu.x.hat.MC\r\n\r\n\r\n[1] 0.265321\r\n\r\nSe obtiene una incertidumbre estándar de calibración de 0.265 mg/L, la cual es consistente con los otros métodos estudiados. La siguiente figura muestra el histograma de las concentraciones simuladas:\r\n\r\n\r\nhist(muestra.MC$x.hat, \r\n     breaks = 20,\r\n     main = 'Concentraciones simuladas por Monte Carlo',\r\n     xlab = 'Concentración [mg/L]')\r\n\r\n\r\n\r\n\r\nFinalmente, la siguiente tabla resume los resultados de los tres métodos considerando la incertidumbre estándar de calibración:\r\n\r\n\r\ntabla <- data.frame(Ix/t, u.GUM$u.y, u.GUM.cov$u.y, u.x.hat.MC)\r\nknitr::kable(tabla, \r\n             rownames = NA,\r\n             col.names = c('ISO', 'GUM', 'GUM/Covarianzas', 'Monte Carlo'),\r\n             align = 'l')\r\n\r\n\r\nISO\r\nGUM\r\nGUM/Covarianzas\r\nMonte Carlo\r\n0.2651904\r\n0.4774807\r\n0.2651904\r\n0.265321\r\n\r\nSe aprecia claramente una excelente concordancia entre los tres métodos. Sin embargo, para que el método GUM entregue resultados correctos, es necesario incorporar las covarianzas entre las variables input.\r\nEn un próximo post exploraremos el método Bootstrap, un método estadístico por excelencia para estimar incertidumbre sin utilizar un modelo de medición…\r\n\r\n¡Dejad que los datos hablen!\r\n\r\nBibliografía\r\nNorma ISO 8466-2:2001 Water quality – Calibration and evaluation of analytical methods and estimation of performance characteristics – Part 2: Calibration strategy for non-linear second-order calibration functions.\r\nBrandon M. Greenwell and Christine M. Schubert Kabban (2014). investr: An R Package for Inverse Estimation. The R Journal, 6(1), 90-100. URL http://journal.r-project.org/archive/2014-1/greenwell-kabban.pdf.\r\nNIST/SEMATECH e-Handbook of Statistical Methods, Uncertainty for quadratic calibration using propagation of error, https://www.itl.nist.gov/div898/handbook/mpc/section3/mpc3671.htm, 09 de junio 2020.\r\nNonlinear multivariate calibration methods in analytical chemistry Sonja Sekulic, Mary Beth Seasholtz, Ziyi Wang, Bruce R. Kowalski, Samuel E. Lee, and Bradley R. Holt Analytical Chemistry 1993 65 (19), 835A-845A\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-23-incertidumbre-no-lineal/incertidumbre-no-lineal_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-03-23T12:05:23-03:00",
    "input_file": {}
  }
]
